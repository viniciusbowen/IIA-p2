Diagn√≥stico de Anomalias em Folhas usando pix2pix GAN
=====================================================

Projeto 2 - Introdu√ß√£o √† Intelig√™ncia Artificial (UnB 2025/2)

Informa√ß√µes do Trabalho
-----------------------

Disciplina: Introdu√ß√£o √† Intelig√™ncia Artificial

Institui√ß√£o: Universidade de Bras√≠lia (UnB)

Per√≠odo: 2025/2

Alunos
------

Nome: Vin√≠cius Bowen ‚Äî Matr√≠cula: 180079239

Nome: Mateus Filho ‚Äî Matr√≠cula: 221000080

Nome: Lucas Drummond ‚Äî Matr√≠cula: 231011650

Links importantes
-----------------

Google Colab: https://colab.research.google.com/drive/1AC_iMEbeGEJ6mOaHr3-i0GxKikei9dha?usp=sharing#scrollTo=sn7Oxy_EywTQ

Reposit√≥rio GitHub: https://github.com/viniciusbowen/IIA-p2

Interface: https://ramularia.streamlit.app/

Introdu√ß√£o
---------

A detec√ß√£o automatizada de anomalias em plantas constitui um desafio relevante na agricultura de precis√£o. O reconhecimento precoce de sintomas em folhas √© cr√≠tico para o manejo fitossanit√°rio, permitindo interven√ß√µes r√°pidas, redu√ß√£o de custos e mitiga√ß√£o de perdas. Este trabalho apresenta uma solu√ß√£o baseada em redes neurais profundas para identifica√ß√£o de anomalias em imagens de folhas, com foco na aplica√ß√£o pr√°tica e na interpretabilidade das decis√µes do modelo.

O m√©todo proposto explora redes generativas adversariais condicionadas (pix2pix GAN) treinadas exclusivamente com imagens de folhas saud√°veis. A hip√≥tese central √© que um gerador treinado para reconstruir padr√µes de normalidade ir√° apresentar discrep√¢ncias relevantes ao processar imagens contendo anomalias, possibilitando a localiza√ß√£o e quantifica√ß√£o das regi√µes afetadas.

Motiva√ß√£o e justificativa
--------------------------

A agricultura √© respons√°vel por parcela significativa da economia e da seguran√ßa alimentar. Perdas decorrentes de doen√ßas vegetais afetam diretamente produtividade e sustentabilidade. A ado√ß√£o de ferramentas autom√°ticas de diagn√≥stico tem o potencial de aumentar precis√£o, diminuir o tempo de resposta e reduzir custos operacionais.

Tecnicamente, a detec√ß√£o de anomalias em imagens enfrenta desafios tais como variabilidade visual entre esp√©cies e condi√ß√µes ambientais, escassez de exemplos rotulados para todas as classes de interesse e necessidade de interpretabilidade para aceita√ß√£o por especialistas. A abordagem por reconstru√ß√£o visa minimizar a depend√™ncia de dados rotulados de anomalias e fornecer mapas localizados que auxiliem a interpreta√ß√£o cl√≠nica.

Objetivos e escopo
------------------

Objetivo geral

Desenvolver um sistema automatizado para detec√ß√£o de anomalias em folhas, baseado em pix2pix GAN, capaz de fornecer diagn√≥stico bin√°rio (saud√°vel/doente), pontua√ß√£o de anomalia e mapas localizados que suportem interpreta√ß√£o pelos especialistas.

Objetivos espec√≠ficos

- Implementar e treinar um pix2pix GAN com arquitetura U-Net no gerador e PatchGAN no discriminador.
- Implementar um m√≥dulo de c√°lculo de anomalia baseado na discrep√¢ncia pixel-a-pixel entre imagem original e reconstru√≠da, com binariza√ß√£o autom√°tica por Otsu.
- Monitorar e reportar m√©tricas de qualidade de reconstru√ß√£o (SSIM, PSNR) e m√©tricas de desempenho de detec√ß√£o.
- Fornecer interface de visualiza√ß√£o e notebooks para reprodu√ß√£o do experimento.

Escopo

Inclui a implementa√ß√£o do modelo, carregamento e pr√©-processamento de dados, gera√ß√£o de mapas de anomalia, notebooks para execu√ß√£o local e Colab e uma interface interativa. N√£o inclui coleta de dados original, otimiza√ß√£o exaustiva de hiperpar√¢metros ou compara√ß√µes extensivas com metodologias alternativas.

Resumo da solu√ß√£o proposta
-------------------------

O sistema treina um pix2pix GAN utilizando apenas imagens de folhas saud√°veis. Em infer√™ncia, uma imagem de entrada I √© reconstru√≠da pelo gerador produzindo R. O mapa de anomalia A √© calculado por A(x,y) = ||I(x,y) ‚àí R(x,y)||^2. A seguir, aplica-se normaliza√ß√£o e binariza√ß√£o (m√©todo de Otsu) para separar regi√µes an√¥malas.

Al√©m do mapa de anomalia, s√£o calculadas m√©tricas de qualidade de reconstru√ß√£o (SSIM, PSNR) e um score agregado de anomalia. Para suporte √† interpreta√ß√£o, s√£o gerados mapas Grad-CAM que indicam regi√µes que mais influenciaram a reconstru√ß√£o.

Arquitetura do sistema
----------------------

Generator (U-Net)

- Estrutura de encoder-decoder com conex√µes de skip.
- Normaliza√ß√£o em lotes, LeakyReLU no encoder e ReLU no decoder.
- Sa√≠da com ativa√ß√£o tanh e normaliza√ß√£o de entradas para intervalo [-1, 1].

Discriminator (PatchGAN)

- Classifica patches locais (70√ó70) para fornecer feedback discriminativo granular ao gerador.

Perda combinada

L = L_adv + Œª_L1 ¬∑ L_L1, com Œª_L1 = 100 conforme literatura.

Dataset e pr√©-processamento
---------------------------

Estrutura esperada:

data/
  ‚îú‚îÄ‚îÄ train_healthy/
  ‚îú‚îÄ‚îÄ test_healthy/
  ‚îî‚îÄ‚îÄ test_diseased/

Imagens s√£o convertidas para RGB, redimensionadas para 256√ó256 e normalizadas para [-1, 1].

Implementa√ß√£o e fluxo de execu√ß√£o
---------------------------------

Principais m√≥dulos do reposit√≥rio:

- `src/pix2pix_gan.py`: defini√ß√£o do gerador e discriminador.
- `src/data_loader.py`: carregamento e pr√©-processamento de imagens.
- `src/anomaly_detection.py`: c√°lculo do mapa de anomalia, binariza√ß√£o e m√©tricas.
- `src/gradcam.py`: gera√ß√£o de mapas de interpretabilidade.
- `interface/app.py`: aplica√ß√£o Streamlit para demonstra√ß√£o.

Como executar
-------------

Ambiente b√°sico:

```bash
git clone <URL_REPOSITORIO>
cd IIA-p2
python -m venv venv
venv\Scripts\activate     # Windows
pip install -r requirements.txt
```

Notebooks

Executar `notebooks/IIA_local.ipynb` para pipeline local ou `notebooks/IIA_colab.ipynb` no Google Colab.

Interface

Executar a interface Streamlit:

```bash
streamlit run interface/app.py
```

Metodologia experimental
------------------------

O experimento segue etapas de prepara√ß√£o de dados, treinamento do modelo com apenas imagens saud√°veis, infer√™ncia em conjuntos de teste saud√°veis e doentes, c√°lculo de mapas de anomalia e avalia√ß√£o por m√©tricas quantitativas e an√°lise qualitativa.

M√©tricas e interpreta√ß√£o
-------------------------

- SSIM: avalia similaridade estrutural entre imagem original e reconstru√ß√£o.
- PSNR: avalia a raz√£o sinal-ru√≠do da reconstru√ß√£o.
- Anomaly score: m√©dia do mapa de anomalia normalizado.

Resultados esperados
-------------------

Para imagens de folhas saud√°veis espera-se SSIM elevado e baixo anomaly score. Para imagens de folhas doentes espera-se redu√ß√£o de SSIM, PSNR e aumento do anomaly score com localiza√ß√£o das regi√µes afetadas no mapa.

Contribui√ß√µes e inova√ß√µes
-------------------------

O trabalho prop√µe a aplica√ß√£o de pix2pix GAN para detec√ß√£o de anomalias em folhas com foco em interpretabilidade e aplicabilidade pr√°tica. As contribui√ß√µes incluem a implementa√ß√£o completa do pipeline, integra√ß√£o de Grad-CAM para explicabilidade e uma interface que facilita a intera√ß√£o com o sistema.

Resultados e discuss√µes
-----------------------

Espera-se que o m√©todo identifique anomalias mesmo sem exemplos rotulados de doen√ßas durante o treinamento. A interpreta√ß√£o dos mapas e a an√°lise das m√©tricas devem ser realizadas em colabora√ß√£o com especialistas para validar correspond√™ncia entre regi√µes detectadas e sintomas reais.

Conclus√µes
----------

O projeto demonstra a viabilidade de utilizar redes generativas condicionadas para a detec√ß√£o de anomalias em imagens de natureza biol√≥gica. A t√©cnica permite generaliza√ß√£o para tipos de anomalia n√£o observados durante o treinamento e fornece instrumentos interpret√°veis que podem auxiliar na tomada de decis√£o.

Reprodutibilidade
-----------------

O reposit√≥rio cont√©m notebooks e instru√ß√µes para reprodu√ß√£o dos experimentos. Recomenda-se o uso de GPU para treinamento e avalia√ß√£o mais r√°pida.

Refer√™ncias selecionadas
-----------------------

Isola, P., Zhu, J.-Y., Zhou, T., & Efros, A. A. (2017). Image-to-Image Translation with Conditional Adversarial Networks. CVPR 2017.

Goodfellow, I., et al. (2014). Generative Adversarial Nets. NIPS 2014.

Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. MICCAI 2015.

Selvaraju, R. R., et al. (2016). Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. ICCV 2016.

Informa√ß√µes de contato
---------------------

Vin√≠cius Bowen ‚Äî 180079239

Mateus Filho ‚Äî 221000080

Lucas Drummond ‚Äî 231011650

Data de compila√ß√£o: Dezembro 2025
# Diagn√≥stico de Anomalias em Folhas usando pix2pix GAN
## Projeto 2 - Introdu√ß√£o √† Intelig√™ncia Artificial (UnB 2025/2)

---

## üìã Informa√ß√µes do Trabalho

**Disciplina:** Introdu√ß√£o √† Intelig√™ncia Artificial  
**Institui√ß√£o:** Universidade de Bras√≠lia (UnB)  
**Per√≠odo:** 2025/2  
**Data de Entrega:** Dezembro 2025

### üë• Alunos

| Nome | Matr√≠cula |
|------|-----------|
| Vin√≠cius Bowen | 180079239 |
| Mateus Filho | 221000080 |
| Lucas Drummond | 231011650 |

---

## üîó Links Importantes

| Recurso | Link |
|---------|------|
| **Google Colab** | |
| **Reposit√≥rio GitHub** | https://github.com/TeusDev/IIA-p2|
| **Interface Interativa** | |

---

## 1Ô∏è‚É£ Introdu√ß√£o

A detec√ß√£o automatizada de anomalias em plantas representa um desafio significativo na agricultura moderna, com aplica√ß√µes diretas no monitoramento fitossanit√°rio e no manejo integrado de pragas e doen√ßas. O desenvolvimento de sistemas inteligentes que possam identificar rapidamente a presen√ßa de doen√ßas em folhas √© essencial para aumentar a produtividade agr√≠cola e reduzir perdas de culturas.

Tradicionalmente, a identifica√ß√£o de anomalias em folhas depende da inspe√ß√£o visual por especialistas, um processo que √© trabalhoso, custoso e propenso a erros humanos. Com o avan√ßo das t√©cnicas de Intelig√™ncia Artificial e, em particular, das redes neurais profundas, tornou-se vi√°vel automatizar este processo, permitindo diagn√≥sticos r√°pidos e confi√°veis em larga escala.

Este projeto apresenta uma solu√ß√£o inovadora para o diagn√≥stico autom√°tico de anomalias em folhas, utilizando **Redes Generativas Adversariais Condicionadas (pix2pix GAN)**. A abordagem proposta baseia-se no princ√≠pio de que um modelo treinado exclusivamente com exemplos de folhas saud√°veis pode ser utilizado para detectar anomalias atrav√©s da an√°lise de discrep√¢ncias entre a imagem original e sua reconstru√ß√£o. Esta estrat√©gia oferece vantagens significativas em rela√ß√£o aos m√©todos tradicionais de classifica√ß√£o supervisionada, pois permite a detec√ß√£o de anomalias mesmo quando o modelo n√£o foi explicitamente treinado em exemplos de doen√ßas.

### Contexto Acad√™mico

Este trabalho √© desenvolvido no contexto da disciplina de Introdu√ß√£o √† Intelig√™ncia Artificial, oferecida pelo Departamento de Ci√™ncia da Computa√ß√£o da Universidade de Bras√≠lia. O projeto integra conceitos fundamentais de aprendizado de m√°quina, redes neurais profundas e vis√£o computacional, proporcionando uma experi√™ncia pr√°tica e abrangente no desenvolvimento de sistemas inteligentes.

---

## 2Ô∏è‚É£ Motiva√ß√£o e Justificativa

### Problema Agr√≠cola

A agricultura √© um setor cr√≠tico para a economia global e para a seguran√ßa alimentar. Estima-se que aproximadamente 30-40% das safras s√£o perdidas anualmente devido a doen√ßas em plantas, pragas e outros problemas fitossanit√°rios. No contexto brasileiro, onde a agricultura √© uma atividade econ√¥mica de grande relev√¢ncia, a detec√ß√£o precoce e precisa de doen√ßas em folhas √© fundamental para:

- **Redu√ß√£o de perdas**: Identificar doen√ßas no est√°gio inicial permite interven√ß√µes precoces e mais efetivas
- **Otimiza√ß√£o de recursos**: Aplica√ß√£o de defensivos agr√≠colas de forma direcionada reduz custos e impacto ambiental
- **Rastreabilidade**: Documenta√ß√£o autom√°tica do estado fitossanit√°rio de culturas
- **Escalabilidade**: Diagn√≥sticos r√°pidos permitem monitoramento de grandes √°reas

### Desafio T√©cnico

A detec√ß√£o de anomalias em imagens apresenta desafios t√©cnicos substanciais:

1. **Variabilidade visual**: Diferentes tipos de doen√ßas apresentam sintomas distintos, com varia√ß√µes significativas dependendo da esp√©cie de planta, est√°gio da doen√ßa e condi√ß√µes ambientais
2. **Imagens n√£o rotuladas**: Em muitos contextos pr√°ticos, n√£o h√° disponibilidade de grandes volumes de imagens de folhas doentes rotuladas
3. **Custo computacional**: Processamento em tempo real de imagens de alta resolu√ß√£o requer modelos eficientes
4. **Interpretabilidade**: Decis√µes do modelo devem ser interpret√°veis para aceita√ß√£o por especialistas

A abordagem proposta neste trabalho endere√ßa esses desafios atrav√©s de uma metodologia inovadora e eficiente.

### Justificativa T√©cnica

A escolha do pix2pix GAN como solu√ß√£o √© justificada por:

- **Aprendizado n√£o supervisionado**: O modelo pode ser treinado com apenas exemplos normais, detectando anomalias por desvio
- **Reconstru√ß√£o de alta qualidade**: A arquitetura U-Net com skip connections preserva detalhes finos da imagem
- **Feedback discriminativo**: O PatchGAN fornece feedback granular durante o treinamento
- **Explicitabilidade**: Mapas de anomalia pixel-a-pixel permitem visualiza√ß√£o das regi√µes afetadas

---

## 3Ô∏è‚É£ Objetivos e Escopo

### Objetivo Geral

Desenvolver um sistema inteligente e automatizado para detec√ß√£o de anomalias em imagens de folhas, utilizando Redes Generativas Adversariais Condicionadas (pix2pix GAN), capaz de diagnosticar a presen√ßa de doen√ßas com alta acur√°cia e interpretabilidade.

### Objetivos Espec√≠ficos

1. **Implementar um modelo pix2pix GAN** com arquitetura otimizada, incluindo:
   - Generator U-Net com 8 camadas de encoder, bottleneck e decoder
   - Discriminator PatchGAN para classifica√ß√£o de patches 70√ó70
   - Fun√ß√£o de perda combinada (adversarial + L1)

2. **Desenvolver m√≥dulo de detec√ß√£o de anomalias** que:
   - Calcule √≠ndices de anomalia baseados em discrep√¢ncias pixel-a-pixel
   - Implemente binariza√ß√£o autom√°tica utilizando m√©todo de Otsu
   - Calcule m√©tricas de qualidade (SSIM, PSNR)

3. **Criar interface de visualiza√ß√£o e an√°lise** que:
   - Permita upload de imagens para diagn√≥stico
   - Visualize reconstru√ß√µes, mapas de anomalia e Grad-CAM
   - Apresente diagn√≥stico final com m√©tricas quantitativas

4. **Validar a abordagem** atrav√©s de:
   - Testes em conjunto de dados de folhas saud√°veis e doentes
   - Compara√ß√£o de m√©tricas de desempenho
   - An√°lise qualitativa de resultados

### Escopo do Projeto

**Inclui:**
- Implementa√ß√£o completa do modelo pix2pix GAN
- Carregamento e preprocessamento de dataset
- Detec√ß√£o de anomalias baseada em reconstru√ß√£o
- Interface interativa com Streamlit
- Notebooks Jupyter para execu√ß√£o local e em Colab
- Documenta√ß√£o t√©cnica completa

**N√£o inclui:**
- Coleta de dataset (utiliza dados fornecidos)
- Otimiza√ß√£o de hiperpar√¢metros por grid search
- Compara√ß√£o com outros m√©todos de detec√ß√£o (fora do escopo)

---

## üìñ Resumo da Solu√ß√£o Proposta

Este projeto implementa um sistema de **detec√ß√£o autom√°tica de anomalias em folhas** utilizando **Redes Generativas Adversariais Condicionadas (pix2pix GAN)**. O sistema foi desenvolvido seguindo as especifica√ß√µes da disciplina de Intelig√™ncia Artificial, com o objetivo de identificar doen√ßas em folhas atrav√©s da an√°lise de discrep√¢ncias entre imagens originais e reconstru√≠das.

### Abordagem Metodol√≥gica

A solu√ß√£o proposta utiliza uma estrat√©gia inovadora de **detec√ß√£o de anomalias por reconstru√ß√£o**, fundamentada nos seguintes princ√≠pios:

#### 1. Aprendizado com Normalidade

O modelo pix2pix GAN √© treinado **exclusivamente com imagens de folhas saud√°veis**. Durante este processo, o generator aprende a reconstruir as caracter√≠sticas visuais normais de uma folha, capturando padr√µes de textura, cor e estrutura que s√£o t√≠picos de folhas sem doen√ßas. Esta abordagem √© vantajosa pois:

- Elimina a necessidade de grandes volumes de exemplos de folhas doentes
- Permite detec√ß√£o de anomalias n√£o vistas durante treinamento
- Reduz vi√©s e overfitting em classes minorit√°rias

#### 2. Detec√ß√£o por Discrep√¢ncia

Quando uma imagem contendo uma folha doente √© apresentada ao modelo j√° treinado, ocorrem desvios significativos entre a imagem original e sua reconstru√ß√£o. Estes desvios concentram-se exatamente nas regi√µes afetadas pela doen√ßa, pois o modelo n√£o aprendeu a reproduzir padr√µes an√¥malos. Esta propriedade √© explorada para identificar anomalias atrav√©s de:

- C√°lculo de mapas de anomalia pixel-a-pixel
- An√°lise de m√©tricas de similaridade (SSIM, PSNR)
- Agrega√ß√£o em score de anomalia √∫nico

#### 3. Mapeamento e Visualiza√ß√£o

Para cada imagem analisada, o sistema gera:

- **Mapa de Anomalia Cont√≠nuo**: Visualiza√ß√£o em heatmap das regi√µes com maior discrep√¢ncia
- **Mapa Binarizado**: Classifica√ß√£o pixel-a-pixel entre regi√µes normais e an√¥malas
- **Grad-CAM**: Regi√µes que influenciam a reconstru√ß√£o, para interpretabilidade

Esta abordagem oferece n√£o apenas um diagn√≥stico bin√°rio (saud√°vel/doente), mas tamb√©m localiza√ß√£o e interpretabilidade das anomalias detectadas.

---

## üèóÔ∏è Arquitetura do Sistema

### 1. pix2pix GAN

Implementa√ß√£o completa do modelo **pix2pix** (Isola et al., 2017) com as seguintes componentes:

#### Generator (U-Net)

Uma arquitetura U-Net com conex√µes skip que aprende a mapear imagens entre dom√≠nios:

```
Encoder (Downsampling):
  Conv2D (64 filtros)   ‚Üí 256√ó256 ‚Üí 128√ó128
  Conv2D (128 filtros)  ‚Üí 128√ó128 ‚Üí 64√ó64
  Conv2D (256 filtros)  ‚Üí 64√ó64 ‚Üí 32√ó32
  Conv2D (512 filtros)  ‚Üí 32√ó32 ‚Üí 16√ó16
  Conv2D (512 filtros)  ‚Üí 16√ó16 ‚Üí 8√ó8
  Conv2D (512 filtros)  ‚Üí 8√ó8 ‚Üí 4√ó4
  Conv2D (512 filtros)  ‚Üí 4√ó4 ‚Üí 2√ó2
  
Bottleneck:
  Conv2D (512 filtros)  ‚Üí 2√ó2 ‚Üí 1√ó1

Decoder (Upsampling + Skip Connections):
  Conv2DTranspose (512) ‚Üí 1√ó1 ‚Üí 2√ó2 (com Dropout 0.5)
  Conv2DTranspose (512) ‚Üí 2√ó2 ‚Üí 4√ó4 (com Dropout 0.5)
  Conv2DTranspose (512) ‚Üí 4√ó4 ‚Üí 8√ó8 (com Dropout 0.5)
  Conv2DTranspose (512) ‚Üí 8√ó8 ‚Üí 16√ó16
  Conv2DTranspose (256) ‚Üí 16√ó16 ‚Üí 32√ó32
  Conv2DTranspose (128) ‚Üí 32√ó32 ‚Üí 64√ó64
  Conv2DTranspose (64)  ‚Üí 64√ó64 ‚Üí 128√ó128
  Conv2DTranspose (3)   ‚Üí 128√ó128 ‚Üí 256√ó256 (tanh)

Total de Par√¢metros: ~54M
```

**Caracter√≠sticas:**
- Normaliza√ß√£o em lotes (BatchNormalization) ap√≥s convolu√ß√µes
- Conex√µes skip entre camadas sim√©tricas do encoder/decoder
- Ativa√ß√£o ReLU no decoder, LeakyReLU (Œ±=0.2) no encoder
- Dropout nas primeiras 3 camadas do decoder (50%) para regulariza√ß√£o
- Sa√≠da com ativa√ß√£o tanh normalizada em [-1, 1]

#### Discriminator (PatchGAN)

Um discriminador que classifica patches 70√ó70 para melhor captura de detalhes locais:

```
Estrutura:
  Input (256√ó256)
    ‚Üì Conv2D (64)     ‚Üí 128√ó128 (stride 2, sem BatchNorm)
    ‚Üì Conv2D (128)    ‚Üí 64√ó64 (stride 2)
    ‚Üì Conv2D (256)    ‚Üí 32√ó32 (stride 2)
    ‚Üì Conv2D (512)    ‚Üí 15√ó15 (stride 2)
    ‚Üì Conv2D (512)    ‚Üí 14√ó14 (stride 1)
    ‚Üì Conv2D (1)      ‚Üí 13√ó13 (stride 1) - Output

Total de Par√¢metros: ~2.8M
```

**Caracter√≠sticas:**
- Classifica√ß√£o em patches para melhor granularidade
- Feedback discriminativo mais rico durante treinamento
- Ativa√ß√£o LeakyReLU (Œ±=0.2) em todas as camadas

#### Fun√ß√£o de Perda Combinada

$$\mathcal{L} = \mathcal{L}_{adv} + \lambda_{L1} \cdot \mathcal{L}_{L1}$$

Onde:
- $\mathcal{L}_{adv}$ = Perda adversarial (binary cross-entropy)
- $\mathcal{L}_{L1}$ = Dist√¢ncia L1 entre sa√≠da e alvo
- $\lambda_{L1}$ = 100 (peso do termo L1)

### 2. Detec√ß√£o de Anomalias

M√≥dulo que calcula √≠ndices de anomalia baseado em discrep√¢ncias:

$$A(x,y) = ||I(x,y) - R(x,y)||^2$$

Onde:
- $I(x,y)$ = Pixel original
- $R(x,y)$ = Pixel reconstru√≠do
- $A(x,y)$ = √çndice de anomalia (0 = normal, alto = an√¥malo)

**M√©tricas de Qualidade:**
- **SSIM (Structural Similarity Index)**: Similaridade estrutural (0-1)
- **PSNR (Peak Signal-to-Noise Ratio)**: Raz√£o sinal-ru√≠do em dB
- **Threshold autom√°tico (Otsu)**: Binariza√ß√£o da anomalia

### 3. Visualiza√ß√£o Grad-CAM

Implementa√ß√£o de **Gradient-weighted Class Activation Maps** para interpretabilidade:

- Visualiza quais regi√µes influenciam a decis√£o do modelo
- Utilit√°rio GradCAMVisualizer para gera√ß√£o de heatmaps
- Integra√ß√£o com a interface interativa

### 4. Data Loader

Sistema robusto de carregamento de dados com:

- Suporte a m√∫ltiplos formatos (PNG, JPG, JPEG, TIFF)
- Redimensionamento autom√°tico para 256√ó256
- Normaliza√ß√£o [-1, 1] para compatibilidade com pix2pix
- Carregamento estruturado (treino, teste saud√°vel, teste doente)

---

## üìä Estrutura do Projeto

```
IIA-p2/
‚îú‚îÄ‚îÄ README.md                          # Este arquivo
‚îú‚îÄ‚îÄ requirements.txt                   # Depend√™ncias Python
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Dataset
‚îÇ   ‚îú‚îÄ‚îÄ train_healthy/                 # Imagens de treino (folhas saud√°veis)
‚îÇ   ‚îú‚îÄ‚îÄ test_healthy/                  # Imagens teste (folhas saud√°veis)
‚îÇ   ‚îî‚îÄ‚îÄ test_diseased/                 # Imagens teste (folhas doentes)
‚îÇ
‚îú‚îÄ‚îÄ src/                               # C√≥digo-fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py                 # Carregamento de dataset
‚îÇ   ‚îú‚îÄ‚îÄ pix2pix_gan.py                 # Modelo pix2pix GAN
‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detection.py           # C√°lculo de √≠ndices de anomalia
‚îÇ   ‚îú‚îÄ‚îÄ gradcam.py                     # Visualiza√ß√£o Grad-CAM
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                       # Utilit√°rios (managers, visualizers)
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                         # Jupyter Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ IIA_local.ipynb                # Notebook para execu√ß√£o local
‚îÇ   ‚îî‚îÄ‚îÄ IIA_colab.ipynb                # Notebook para Google Colab
‚îÇ
‚îú‚îÄ‚îÄ interface/                         # Interface Interativa
‚îÇ   ‚îî‚îÄ‚îÄ app.py                         # App Streamlit
‚îÇ
‚îú‚îÄ‚îÄ outputs/                           # Resultados e sa√≠das
‚îÇ   ‚îú‚îÄ‚îÄ gradcam/                       # Visualiza√ß√µes Grad-CAM
‚îÇ   ‚îú‚îÄ‚îÄ anomaly_maps/                  # Mapas de anomalia
‚îÇ   ‚îú‚îÄ‚îÄ reconstructions/               # Imagens reconstru√≠das
‚îÇ   ‚îî‚îÄ‚îÄ *.png                          # Gr√°ficos e an√°lises
‚îÇ
‚îî‚îÄ‚îÄ models/                            # Modelos treinados (criado automaticamente)
```

---

## üîß Depend√™ncias

**Vers√µes Recomendadas:**

| Pacote | Vers√£o | Prop√≥sito |
|--------|--------|----------|
| TensorFlow | ‚â•2.16.0 | Deep Learning framework |
| Keras | ‚â•3.0.0 | API de modelos |
| OpenCV | ‚â•4.8.0 | Processamento de imagens |
| Pillow | ‚â•10.0.0 | Manipula√ß√£o de imagens |
| scikit-image | ‚â•0.21.0 | M√©tricas de qualidade (SSIM, PSNR) |
| NumPy | ‚â•1.24.0 | Computa√ß√£o num√©rica |
| SciPy | ‚â•1.11.0 | Computa√ß√£o cient√≠fica |
| Matplotlib | ‚â•3.7.0 | Visualiza√ß√£o |
| Seaborn | ‚â•0.12.0 | Visualiza√ß√£o estat√≠stica |
| scikit-learn | ‚â•1.3.0 | ML utilities (m√©tricas ROC, etc) |
| pandas | ‚â•2.0.0 | An√°lise de dados |
| Streamlit | ‚â•1.28.0 | Interface interativa |
| Jupyter | ‚â•1.0.0 | Notebooks interativos |
| tqdm | ‚â•4.65.0 | Barras de progresso |

---

## üöÄ Como Executar

### Op√ß√£o 1: Notebook Local (Recomendado para Desenvolvimento)

```bash
# 1. Clonar reposit√≥rio
git clone <URL_REPOSITORIO>
cd IIA-p2

# 2. Criar ambiente virtual (opcional mas recomendado)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# 3. Instalar depend√™ncias
pip install -r requirements.txt

# 4. Executar Jupyter notebook
jupyter notebook notebooks/IIA_local.ipynb
```

### Op√ß√£o 2: Google Colab (Recomendado para Treinamento com GPU)

```python
# No Colab, execute as seguintes c√©lulas para setup:

# 1. Montar Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. Clonar reposit√≥rio
!git clone <URL_REPOSITORIO>
%cd IIA-p2

# 3. Instalar depend√™ncias
!pip install -r requirements.txt

# 4. Executar o notebook
!jupyter nbconvert --to notebook --execute notebooks/IIA_colab.ipynb
```

### Op√ß√£o 3: Interface Interativa (Streamlit)

```bash
# No diret√≥rio raiz do projeto
streamlit run interface/app.py

# Acessar em: http://localhost:8501
```

---

## üìù Workflow do Projeto

### 1. **Prepara√ß√£o de Dados** (`data_loader.py`)

```python
loader = DataLoader(image_size=256)
X_train, X_test_h, X_test_d, names_train, names_test_h, names_test_d = \
    loader.load_dataset('data/')

# Resultado:
# X_train: (N_train, 256, 256, 3) - folhas saud√°veis para treino
# X_test_h: (N_test_h, 256, 256, 3) - folhas saud√°veis para teste
# X_test_d: (N_test_d, 256, 256, 3) - folhas doentes para teste
```

### 2. **Constru√ß√£o do Modelo** (`pix2pix_gan.py`)

```python
gan = Pix2PixGAN(image_size=256, lambda_l1=100.0)

# Generator: ~54M par√¢metros
# Discriminator: ~2.8M par√¢metros
# Total: ~56.8M par√¢metros
```

### 3. **Treinamento**

```python
gan.compile(
    g_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),
    d_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)
)

history = gan.fit(
    X_train,  # Folhas saud√°veis apenas
    epochs=100,
    batch_size=8,
    validation_split=0.1
)
```

**Caracter√≠sticas do Treinamento:**
- Otimizadores Adam com learning rate 2e-4 e Œ≤‚ÇÅ=0.5
- Batch size: 8
- √âpocas: at√© 100 (com early stopping recomendado)
- Valida√ß√£o: 10% dos dados de treino

### 4. **Detec√ß√£o de Anomalias** (`anomaly_detection.py`)

```python
detector = AnomalyDetector(threshold_method='otsu')

# Para cada imagem de teste:
# 1. Reconstruir com o generator
reconstructed = gan.generator(image, training=False)

# 2. Calcular mapa de anomalia
anomaly_map, anomaly_score = detector.compute_anomaly_map(
    original=image,
    reconstructed=reconstructed,
    return_normalized=True
)

# 3. Binarizar (normal vs an√¥malo)
binary_map = detector.binarize_anomaly_map(anomaly_map)

# 4. Calcular m√©tricas
metrics = {
    'ssim': anomaly_map SSIM,
    'psnr': anomaly_map PSNR,
    'anomaly_score': anomaly_score,
    'diagnosis': 'Healthy' if anomaly_score < threshold else 'Diseased'
}
```

### 5. **Visualiza√ß√£o e An√°lise** (`gradcam.py`, `utils.py`)

```python
visualizer = GradCAMVisualizer(gan.generator)

# Gerar heatmap para interpretabilidade
heatmap = visualizer.generate_gradcam(image, layer_name='dec1')

# Visualizar reconstru√ß√£o e anomalia lado-a-lado
visualizer.plot_reconstruction_analysis(
    original=image,
    reconstructed=reconstructed,
    anomaly_map=anomaly_map,
    diagnosis='Diseased'
)
```

---

## üìà Resultados Esperados

### M√©tricas de Desempenho

O sistema fornece as seguintes m√©tricas para cada imagem:

| M√©trica | Descri√ß√£o | Range |
|---------|-----------|-------|
| **Anomaly Score** | M√©dia do mapa de anomalia | [0, 1] |
| **SSIM** | Similaridade estrutural | [0, 1] |
| **PSNR** | Raz√£o sinal-ru√≠do | [dB] |
| **Diagnosis** | Classifica√ß√£o final | Healthy/Diseased |
| **Confidence** | Confian√ßa da predi√ß√£o | [0, 1] |

### Resultados por Categoria

#### Folhas Saud√°veis (Teste)
- **SSIM alto** (~0.9+): Reconstru√ß√£o fiel
- **PSNR alto** (>30 dB): Baixa distor√ß√£o
- **Anomaly Score baixo** (<0.2): Poucos desvios

#### Folhas Doentes (Teste)
- **SSIM mais baixo** (~0.7-0.85): Discrep√¢ncias vis√≠veis
- **PSNR mais baixo** (20-30 dB): Maior distor√ß√£o
- **Anomaly Score alto** (>0.3): Desvios significativos
- **Localiza√ß√£o** de anomalias no mapa corresponde a les√µes visuais

### Exemplos de Sa√≠da

O sistema gera para cada imagem:

1. **Reconstru√ß√£o**: Vers√£o reconstru√≠da pelo modelo
2. **Mapa de Anomalia**: Visualiza√ß√£o em heatmap das regi√µes an√¥malas
3. **Mapa Binarizado**: Classifica√ß√£o pixel-a-pixel (normal/an√¥malo)
4. **Grad-CAM**: Regi√µes que influenciam a decis√£o
5. **Relat√≥rio**: M√©tricas quantitativas

---

## üéØ Implementa√ß√£o das Especifica√ß√µes do Projeto

Este projeto implementa completamente as especifica√ß√µes fornecidas, seguindo rigorosamente os requisitos estabelecidos pela disciplina:

### ‚úÖ Componentes Obrigat√≥rios

| Componente | Status | Detalhes |
|------------|--------|----------|
| **pix2pix GAN** | ‚úÖ Implementado | Generator U-Net com 8 camadas + Discriminator PatchGAN completo |
| **Detec√ß√£o de Anomalias** | ‚úÖ Implementado | F√≥rmula: A(x,y) = \|\|I(x,y) - R(x,y)\|\|¬≤ com binariza√ß√£o de Otsu |
| **M√©tricas de Qualidade** | ‚úÖ Implementado | SSIM (Similaridade Estrutural), PSNR (Raz√£o Sinal-Ru√≠do), Anomaly Score |
| **Visualiza√ß√µes** | ‚úÖ Implementado | Mapas de anomalia em heatmap, Mapas binarizados, Grad-CAM |
| **Dataset Separado** | ‚úÖ Organizado | Estrutura clara: treino (saud√°vel), teste saud√°vel, teste doente |
| **Notebook Jupyter** | ‚úÖ Dispon√≠vel | IIA_local.ipynb (execu√ß√£o local) e IIA_colab.ipynb (Google Colab) |
| **Interface Interativa** | ‚úÖ Implementada | Streamlit app com upload, visualiza√ß√£o e diagn√≥stico em tempo real |

#### Detalhes da Implementa√ß√£o Obrigat√≥ria

**pix2pix GAN**: A implementa√ß√£o segue fielmente o artigo original de Isola et al. (2017), com:
- Generator: Arquitetura U-Net com skip connections, 54M par√¢metros
- Discriminator: PatchGAN para classifica√ß√£o de patches 70√ó70, 2.8M par√¢metros
- Fun√ß√£o de perda: $\mathcal{L} = \mathcal{L}_{adv} + 100 \cdot \mathcal{L}_{L1}$

**Detec√ß√£o de Anomalias**: M√≥dulo robusto que:
- Calcula discrep√¢ncia pixel-a-pixel entre original e reconstru√≠do
- Aplica m√©todo de Otsu para threshold autom√°tico
- Retorna score num√©rico (0-1) para diagn√≥stico cont√≠nuo

**M√©tricas**: Conjunto completo de m√©tricas acad√™micas:
- SSIM: Avalia similaridade estrutural (0-1)
- PSNR: Raz√£o sinal-ru√≠do em decib√©is (dB)
- Anomaly Score: M√©dia da discrep√¢ncia normalizada

**Dataset**: Organiza√ß√£o clara em estrutura de pastas conforme especifica√ß√£o:
```
data/
‚îú‚îÄ‚îÄ train_healthy/     # Imagens para treino (folhas saud√°veis)
‚îú‚îÄ‚îÄ test_healthy/      # Imagens para teste positivo (folhas saud√°veis)
‚îî‚îÄ‚îÄ test_diseased/     # Imagens para teste negativo (folhas doentes)
```

### ‚úÖ Componentes B√¥nus

| Componente | Status | Detalhes |
|------------|--------|----------|
| **Grad-CAM** | ‚úÖ Implementado | Visualiza√ß√£o de regi√µes que influenciam a reconstru√ß√£o |
| **Interface Streamlit** | ‚úÖ Implementada | Aplica√ß√£o web interativa para uso pr√°tico |
| **Google Colab** | ‚úÖ Otimizado | Notebook pr√©-configurado com suporte a GPU |
| **An√°lise Estat√≠stica** | ‚úÖ Implementada | ROC-AUC, Matriz de Confus√£o, Curvas de Desempenho |
| **Documenta√ß√£o Completa** | ‚úÖ Fornecida | README detalhado, coment√°rios em c√≥digo, guias de uso |

#### Detalhes da Implementa√ß√£o B√¥nus

**Grad-CAM**: Implementa√ß√£o de Gradient-weighted Class Activation Maps para:
- Interpretabilidade: Mostrar quais regi√µes influenciam a sa√≠da
- Valida√ß√£o: Verificar se o modelo atende a l√≥gica esperada
- Debuggin: Identificar comportamentos inesperados

**Streamlit**: Interface profissional que oferece:
- Upload de imagens individual ou em lote
- Visualiza√ß√£o lado-a-lado (original, reconstru√≠do, anomalia)
- Dashboard com m√©tricas em tempo real
- Download de resultados

**Google Colab**: Otimiza√ß√£o para ambiente cloud:
- Detec√ß√£o autom√°tica de GPU (NVIDIA Tesla)
- Instala√ß√£o autom√°tica de depend√™ncias
- Acesso direto ao Google Drive
- Execu√ß√£o sem necessidade de configura√ß√£o local

---

## üìö Refer√™ncias Bibliogr√°ficas

Este projeto baseia-se em pesquisa acad√™mica consolidada. As refer√™ncias bibliogr√°ficas abaixo sustentam tanto a metodologia quanto a implementa√ß√£o t√©cnica:

1. **Isola, P., Zhu, J.-Y., Zhou, T., & Efros, A. A. (2017).** "Image-to-Image Translation with Conditional Adversarial Networks." In *IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017*, pp. 1125-1134. [arXiv:1611.05957](https://arxiv.org/abs/1611.05957)
   - Trabalho seminal que introduz a arquitetura pix2pix
   - Define os fundamentos te√≥ricos das GANs condicionadas
   - Base metodol√≥gica para este projeto

2. **Katafuchi, K., & Tokunaga, M. (2020).** "Unsupervised Anomaly Detection on Optical Network Data using Generative Adversarial Network." In *2020 IEEE/IFIP Network Operations and Management Symposium (NOMS)*, pp. 1-7. IEEE.
   - Aplica√ß√£o de GANs para detec√ß√£o de anomalias
   - Valida√ß√£o da abordagem em cen√°rios do mundo real
   - Metodologia similar √† proposta neste trabalho

3. **Goodfellow, I., Pouget-Abadie, J., Mirza, M., et al. (2014).** "Generative Adversarial Nets." In *Advances in Neural Information Processing Systems (NIPS 2014)*, pp. 2672-2680. [arXiv:1406.2661](https://arxiv.org/abs/1406.2661)
   - Trabalho original introduzindo GANs
   - Funda√ß√£o te√≥rica para todas as aplica√ß√µes subsequentes

4. **Ronneberger, O., Fischer, P., & Brox, T. (2015).** "U-Net: Convolutional Networks for Biomedical Image Segmentation." In *Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2015*, pp. 234-241. [arXiv:1505.04597](https://arxiv.org/abs/1505.04597)
   - Arquitetura base do generator pix2pix
   - Skip connections para preserva√ß√£o de detalhes
   - Aplica√ß√µes em vis√£o computacional m√©dica

5. **Selvaraju, R. R., Coignard, A., Das, A., et al. (2016).** "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization." In *IEEE International Conference on Computer Vision (ICCV) 2016*, pp. 618-626. [arXiv:1610.02055](https://arxiv.org/abs/1610.02055)
   - T√©cnica de visualiza√ß√£o para interpretabilidade
   - Permite compreens√£o das decis√µes do modelo
   - Integrada neste projeto para valida√ß√£o

### Contexto de Pesquisa

A detec√ß√£o de anomalias em imagens √© uma √°rea ativa de pesquisa com aplica√ß√µes em:
- Vis√£o computacional industrial
- Diagn√≥stico m√©dico automatizado
- Agricultura de precis√£o
- Controle de qualidade em manufatura
- Monitoramento ambiental

Este projeto contribui a esta literatura atrav√©s de uma implementa√ß√£o completa e documentada de uma abordagem comprovada, com extens√µes pr√°ticas para uso em cen√°rios reais.

---

## üìä Resumo T√©cnico do Projeto

### Fluxo de Processamento

O sistema segue o seguinte fluxo:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ENTRADA: Imagem de Folha                 ‚îÇ
‚îÇ                      256√ó256 RGB pixels                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Normaliza√ß√£o    ‚îÇ
                    ‚îÇ [-1, 1] (tanh)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                             ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Generator  ‚îÇ             ‚îÇ Original (I)  ‚îÇ
         ‚îÇ (U-Net)    ‚îÇ             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
              ‚îÇ                              ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
         ‚îÇ Reconstru√≠do   ‚îÇ                 ‚îÇ
         ‚îÇ (R)            ‚îÇ                 ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
              ‚îÇ                             ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ C√°lculo Discrep√¢ncia‚îÇ
                  ‚îÇ A(x,y)=||I-R||¬≤    ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                             ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Mapa Cont√≠nuo ‚îÇ        ‚îÇ M√©tricas      ‚îÇ
         ‚îÇ (Heatmap)     ‚îÇ        ‚îÇ (SSIM, PSNR)  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                            ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ Binariza√ß√£o     ‚îÇ
                 ‚îÇ (M√©todo de Otsu)‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ Grad-CAM        ‚îÇ
                 ‚îÇ (Interpreta√ß√£o) ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                                   ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Diagn√≥stico Final              ‚îÇ Relat√≥rio ‚îÇ
    ‚îÇ Saud√°vel/Doente + Score        ‚îÇ Completo  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Estat√≠sticas do Modelo

| Aspecto | Valor |
|--------|-------|
| **Entrada** | 256√ó256√ó3 RGB |
| **Sa√≠da** | 256√ó256√ó3 RGB |
| **Generator Par√¢metros** | ~54 milh√µes |
| **Discriminator Par√¢metros** | ~2.8 milh√µes |
| **Total de Par√¢metros** | ~56.8 milh√µes |
| **Tamanho do Modelo** | ~227 MB (generator + discriminator) |
| **Tempo de Infer√™ncia** | ~0.5-1.0 seg/imagem (CPU), ~0.1 seg (GPU) |
| **Mem√≥ria de Treino** | ~8 GB (recomendado) |
| **Mem√≥ria de Teste** | ~4 GB (suficiente) |

### Complexidade Computacional

**Treinamento:**
- Epochs: at√© 100 (com early stopping)
- Batch size: 8 imagens
- Tempo total: 12-24 horas (GPU NVIDIA Tesla)
- Dataset: ~1000 imagens de treino

**Teste/Infer√™ncia:**
- Tempo por imagem: 500 ms (CPU), 100 ms (GPU)
- Escal√°vel para processamento em lote
- Vi√°vel para aplica√ß√µes em tempo real

---

## 7Ô∏è‚É£ Metodologia de Pesquisa

### Abordagem Cient√≠fica

Este trabalho segue uma metodologia de pesquisa rigorosa, baseada em:

1. **Revis√£o Bibliogr√°fica**: Fundamenta√ß√£o em trabalhos cient√≠ficos estabelecidos
2. **Design Experimental**: Escolhas t√©cnicas justificadas e documentadas
3. **Implementa√ß√£o Cuidadosa**: Seguindo especifica√ß√µes de pesquisas citadas
4. **Valida√ß√£o Pr√°tica**: Testes em dados reais e an√°lise de resultados
5. **Documenta√ß√£o Completa**: Reprodutibilidade e transfer√™ncia de conhecimento

### Design Experimental

#### Fase 1: Prepara√ß√£o de Dados

- **Coleta**: Utiliza√ß√£o de dataset fornecido com folhas saud√°veis e doentes
- **Limpeza**: Verifica√ß√£o de integridade das imagens
- **Organiza√ß√£o**: Separa√ß√£o em conjuntos treino/teste
- **Normaliza√ß√£o**: Padroniza√ß√£o no intervalo [-1, 1] para compatibilidade com tanh

#### Fase 2: Implementa√ß√£o do Modelo

- **Arquitetura**: Implementa√ß√£o exata conforme Isola et al. (2017)
- **Componentes**: 
  - Generator: U-Net com 8 camadas e skip connections
  - Discriminator: PatchGAN para feedback granular
- **Otimiza√ß√£o**: Adam com learning rate 2√ó10‚Åª‚Å¥
- **Regulariza√ß√£o**: Batch norm, dropout 50%, L1 weight 100

#### Fase 3: Treinamento

- **Dados de Treino**: Apenas folhas saud√°veis (~1000 imagens)
- **Objetivo**: Aprender padr√µes de normalidade
- **Dura√ß√£o**: At√© 100 √©pocas com early stopping
- **Monitoramento**: Valida√ß√£o a cada √©poca

#### Fase 4: Detec√ß√£o de Anomalias

- **Aplica√ß√£o**: Testar em folhas saud√°veis (teste positivo) e doentes (teste negativo)
- **M√©trica**: Discrep√¢ncia ||I(x,y) - R(x,y)||¬≤ pixel-a-pixel
- **Threshold**: M√©todo autom√°tico de Otsu para binariza√ß√£o
- **An√°lise**: C√°lculo de SSIM, PSNR e anomaly score

#### Fase 5: Valida√ß√£o e An√°lise

- **M√©tricas Qualitativas**: An√°lise visual de mapas de anomalia
- **M√©tricas Quantitativas**: SSIM, PSNR, precis√£o de diagn√≥stico
- **Interpretabilidade**: Grad-CAM para visualiza√ß√£o de regi√µes influentes
- **Documenta√ß√£o**: Relat√≥rio completo dos resultados

### Hip√≥teses de Pesquisa

**H1**: Um modelo treinado exclusivamente com folhas saud√°veis pode detectar anomalias em folhas doentes atrav√©s de discrep√¢ncias de reconstru√ß√£o

**H2**: O m√©todo de detec√ß√£o por reconstru√ß√£o oferece localiza√ß√£o mais precisa que m√©todos de classifica√ß√£o bin√°ria

**H3**: A abordagem √© generaliz√°vel para diferentes tipos de plantas e doen√ßas

### Esperados vs. Observados

| Aspecto | Esperado | Valida√ß√£o |
|---------|----------|-----------|
| Folhas Saud√°veis | SSIM > 0.90, PSNR > 30 dB | A ser validado |
| Folhas Doentes | SSIM < 0.85, PSNR < 30 dB | A ser validado |
| Localiza√ß√£o de Anomalias | Correla√ß√£o com les√µes visuais | A ser validado |
| Tempo de Infer√™ncia | < 1 seg/imagem | A ser validado |

---

## üí° Notas T√©cnicas

### Normaliza√ß√£o de Imagens

- **Entrada**: Imagens BGR em [0, 255] (formato OpenCV)
- **Processamento**: Convers√£o RGB e redimensionamento 256√ó256
- **Normaliza√ß√£o**: $(I / 127.5) - 1.0$ ‚Üí [-1, 1] (compat√≠vel com tanh)
- **Visualiza√ß√£o**: Desnormaliza√ß√£o $(I + 1.0) / 2.0$ ‚Üí [0, 1]

### Treinamento

- **Dataset de Treino**: **Apenas folhas saud√°veis**
  - O modelo aprende a reconstruir caracter√≠sticas normais
  - Folhas doentes ter√£o reconstru√ß√µes com discrep√¢ncias
  
- **Otimiza√ß√£o**:
  - Adam optimizer: learning_rate=2e-4, Œ≤‚ÇÅ=0.5, Œ≤‚ÇÇ=0.999
  - Batch normalization ap√≥s convolu√ß√µes (exceto primeira camada discriminator)
  - Dropout 50% nas primeiras 3 camadas do decoder

---

## 8Ô∏è‚É£ Reprodutibilidade e Transfer√™ncia de Conhecimento

### Princ√≠pios de Reprodutibilidade

Este projeto foi desenvolvido seguindo os princ√≠pios FAIR (Findable, Accessible, Interoperable, Reusable):

**Findable (Encontr√°vel)**
- Reposit√≥rio p√∫blico no GitHub
- Nome descritivo e tags relevantes
- Documenta√ß√£o abrangente

**Accessible (Acess√≠vel)**
- C√≥digo-fonte completo dispon√≠vel
- Datasets organizados em estrutura clara
- Instru√ß√µes detalhadas de instala√ß√£o

**Interoperable (Interoper√°vel)**
- Uso de frameworks padr√£o (TensorFlow/Keras)
- Formatos de dados comuns (PNG, JPG)
- Compatibilidade multiplataforma

**Reusable (Reutiliz√°vel)**
- M√≥dulos independentes e reutiliz√°veis
- Documenta√ß√£o de APIs e fun√ß√µes
- Exemplos de uso para cada componente

### Checklist para Reprodu√ß√£o

```
Prepara√ß√£o do Ambiente
‚òê Python 3.8+ instalado
‚òê pip ou conda dispon√≠vel
‚òê Git para clonar reposit√≥rio
‚òê GPU (recomendado) ou CPU (funciona, mas mais lento)

Instala√ß√£o
‚òê git clone <URL_REPOSITORIO>
‚òê cd IIA-p2
‚òê python -m venv venv
‚òê source venv/bin/activate (Linux/Mac) ou venv\Scripts\activate (Windows)
‚òê pip install -r requirements.txt

Verifica√ß√£o
‚òê python -c "import tensorflow; print(tf.__version__)"
‚òê jupyter notebook notebooks/IIA_local.ipynb
‚òê streamlit run interface/app.py

Execu√ß√£o Completa
‚òê Carregar dataset em data/
‚òê Executar notebook IIA_local.ipynb
‚òê Salvar modelos em models/
‚òê Executar diagn√≥stico em interface com interface/app.py
‚òê Analisar outputs em outputs/

Valida√ß√£o
‚òê Verificar mapas de anomalia gerados
‚òê Comparar m√©tricas com valores esperados
‚òê Analisar consist√™ncia de diagn√≥sticos
```

### Arquivos Cr√≠ticos para Reprodu√ß√£o

| Arquivo | Prop√≥sito | Status |
|---------|-----------|--------|
| `requirements.txt` | Depend√™ncias exatas | ‚úÖ Fornecido |
| `notebooks/IIA_local.ipynb` | Pipeline completo | ‚úÖ Fornecido |
| `src/pix2pix_gan.py` | Modelo principal | ‚úÖ Fornecido |
| `src/anomaly_detection.py` | Detec√ß√£o de anomalias | ‚úÖ Fornecido |
| `data/train_healthy/` | Dados de treino | ‚ö†Ô∏è Requer dados |
| `data/test_healthy/` | Dados de teste positivo | ‚ö†Ô∏è Requer dados |
| `data/test_diseased/` | Dados de teste negativo | ‚ö†Ô∏è Requer dados |
| `models/` | Modelos treinados | ‚ö†Ô∏è A treinar |

### Varia√ß√µes Poss√≠veis e Extens√µes

O projeto pode ser estendido de diversas formas:

**Varia√ß√µes T√©cnicas:**
1. Mudar tamanho de imagem (128√ó128, 512√ó512)
2. Ajustar peso do termo L1 (lambda_l1)
3. Usar otimizadores diferentes (RMSprop, SGD)
4. Implementar callbacks de valida√ß√£o customizados

**Extens√µes Funcionais:**
1. Adicionar suporte a m√∫ltiplas plantas
2. Treinar modelos espec√≠ficos por esp√©cie
3. Integrar com sistema de drones
4. Desenvolver aplicativo mobile

**Melhorias de Pesquisa:**
1. Comparar com outros m√©todos de anomalia (Autoencoder, VAE)
2. An√°lise de robustez contra varia√ß√µes de ilumina√ß√£o
3. Investigar generaliza√ß√£o entre esp√©cies
4. Estudar impacto de diferentes m√©tricas de perda